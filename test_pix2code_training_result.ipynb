{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision, numpy as np\n",
        "from pix2code_resnet18_free import Vocabulary, Pix2codeDataset, collate_fn, EncoderCNN, DecoderRNN"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1     # length of test dataset\n",
        "num_workers = 1\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "crop_size = 224\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Paths\n",
        "data_path = \"../data/data_bootstrap/\"\n",
        "#train_path = data_path + \"processed_data/data_train/\"\n",
        "test_path = data_path + \"processed_data/data_test/\"\n",
        "vocab_path = data_path + \"bootstrap.vocab\""
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(vocab_path, 'r') as file:\n",
        "    content = file.read()\n",
        "words = content.split(' '); del content\n",
        "len(words)\n",
        "\n",
        "vocab = Vocabulary()\n",
        "for word in words:\n",
        "    vocab.add_word(word)\n",
        "vocab.add_word(' ')\n",
        "vocab.add_word('<unk>') # if we find an unknown word\n",
        "vocab_size = len(vocab)\n",
        "print(f\"total length of vocab is : {vocab_size}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total length of vocab is : 19\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%  Transform to modify images for pre-trained ResNet base and train_dataset\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((crop_size, crop_size)), # Match resnet size\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    # See for : http://pytorch.org/docs/master/torchvision/models.html\n",
        "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "test_dataset = Pix2codeDataset(data_path=test_path, vocab=vocab, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
        "                         shuffle=True, num_workers=num_workers, collate_fn=collate_fn)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset of   175 items from\n",
            "../data/data_bootstrap/processed_data/data_test/\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model parameters saved\n",
        "\ntrained 100 epochs "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = EncoderCNN(embed_size).to(device)\n",
        "decoder = DecoderRNN(embed_size, hidden_size, len(vocab), num_layers).to(device)\n",
        "\n",
        "folder_ = \"./Logs/2018-08-04-03-40-07/\"\n",
        "epoch_ = 100\n",
        "encoder.load_state_dict(torch.load(f\"{folder_}encoder_epoch{epoch_}.pkl\",map_location='cpu'))\n",
        "decoder.load_state_dict(torch.load(f\"{folder_}decoder_epoch{epoch_}.pkl\",map_location='cpu'))"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index in target[1:-1].numpy().astype(int):\n",
        "    print(vocab.idx2word[index], end=\"\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "header{btn-active,btn-inactive,btn-inactive,btn-inactive}row{quadruple{small-title,text,btn-orange}quadruple{small-title,text,btn-green}quadruple{small-title,text,btn-orange}quadruple{small-title,text,btn-orange}}row{double{small-title,text,btn-orange}double{small-title,text,btn-red}}"
          ]
        }
      ],
      "execution_count": 39,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for j, data in enumerate(test_loader):\n",
        "    # (images_test, captions_test, lengths_test)\n",
        "    print(j)\n",
        "    #features = encoder(images_test)\n",
        "    #features"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n"
          ]
        }
      ],
      "execution_count": 47,
      "metadata": {
        "collapsed": false,
        "outputHidden": true,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, captions, lengths in test_loader:\n",
        "    #print(images.size())\n",
        "    features = encoder(images)\n",
        "    #print(features.size())\n",
        "    break\n",
        "sampled_ids = []\n",
        "inputs = features.unsqueeze(1)\n",
        "inputs.size()\n",
        "states = None\n",
        "for i in range(77):\n",
        "    hiddens, states = decoder.lstm(inputs, states)\n",
        "    outputs = decoder.fc(hiddens.squeeze(1))\n",
        "    _, predicted = outputs.max(1)\n",
        "    sampled_ids.append(predicted)\n",
        "    inputs = decoder.embed(predicted)\n",
        "    inputs = inputs.unsqueeze(1)\n",
        "sampled_ids = torch.stack(sampled_ids, 1)  \n",
        "sampled_ids.size()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": [
              "torch.Size([2, 77])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1\n",
        "print(sampled_ids[n,:])\n",
        "print(captions[n,:])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 12,  13,   1,   7,   0,  14,   0,   7,   2,   6,   1,   5,\n",
            "          1,   3,   0,   4,   0,   8,   2,   5,   1,   3,   0,   4,\n",
            "          0,   8,   2,   5,   1,   3,   0,   4,   0,   8,   2,   5,\n",
            "          1,   3,   0,   4,   0,   8,   2,   2,   6,   1,  11,   1,\n",
            "          3,   0,   4,   0,   8,   2,  11,   1,   3,   0,   4,   0,\n",
            "          8,   2,   2,  15,  15,  15,  12,  13,   1,   7,   0,   7,\n",
            "          0,   7,   0,  14,   0])\n",
            "tensor([ 12,  13,   1,   7,   0,  14,   0,   7,   2,   6,   1,  11,\n",
            "          1,   3,   0,   4,   0,   8,   2,  11,   1,   3,   0,   4,\n",
            "          0,   9,   2,   2,   6,   1,   5,   1,   3,   0,   4,   0,\n",
            "          8,   2,   5,   1,   3,   0,   4,   0,  10,   2,   5,   1,\n",
            "          3,   0,   4,   0,   8,   2,   5,   1,   3,   0,   4,   0,\n",
            "         10,   2,   2,   6,   1,  18,   1,   3,   0,   4,   0,   9,\n",
            "          2,   2,  15])\n"
          ]
        }
      ],
      "execution_count": 44,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model saved\n",
        "\n100 epochs pretrained + further 200 epochs"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam optimizer"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = torch.load(\"./Logs/20180805-123547/encoder_epoch199.pkl\")\n",
        "decoder = torch.load(\"./Logs/20180805-123547/decoder_epoch199.pkl\")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_list = []\n",
        "caption_list = []\n",
        "\n",
        "for images, captions, lengths in test_loader:\n",
        "    features = encoder(images)\n",
        "    caption_list.append(captions.numpy()[0,:].tolist())   # there is an extra batch dimension\n",
        "    \n",
        "    sampled_ids = []\n",
        "    inputs = features.unsqueeze(1)\n",
        "    states = None\n",
        "    for i in range(100):            # predict 100 words at most\n",
        "        # predict    \n",
        "        hiddens, states = decoder.lstm(inputs, states)\n",
        "        outputs = decoder.fc(hiddens.squeeze(1))\n",
        "        _, predicted = outputs.max(1)\n",
        "        \n",
        "        # store prediction\n",
        "        sampled_ids.append(predicted.item())\n",
        "        \n",
        "        # if predicts <END>, break\n",
        "        # 把15(<END>)后面的单词全部设为0，因为训练中并没有教模型15以后的时序列应该怎么预测\n",
        "        if sampled_ids[-1] == vocab.word2idx['<END>']:\n",
        "            break\n",
        "        \n",
        "        # prediction as the next input\n",
        "        inputs = decoder.embed(predicted)\n",
        "        inputs = inputs.unsqueeze(1)\n",
        "        \n",
        "    prediction_list.append(sampled_ids)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "save incorrect prediction"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "info = \"\"\n",
        "for i in range(len(prediction_list)):\n",
        "    info_ = \"[{:4d}/{:4d}] :\\n\".format( i+1,len(prediction_list) )\n",
        "    \n",
        "    count = 0\n",
        "    if len(prediction_list[i]) > len(caption_list[i]):\n",
        "        for n in range(len(prediction_list[i])):\n",
        "            if n >= len(caption_list[i]):\n",
        "                info_ += \"\\t\\t{:10s} \\t-->\\t {:10s}\\n\".format(\"None\", vocab.idx2word[prediction_list[i][n]])\n",
        "                count += 1\n",
        "            elif prediction_list[i][n] != caption_list[i][n]:\n",
        "                info_ += \"\\t\\t{:10s} \\t-->\\t {:10s}\\n\".format(vocab.idx2word[caption_list[i][n]], vocab.idx2word[prediction_list[i][n]])\n",
        "                count += 1\n",
        "            else:\n",
        "                pass\n",
        "    \n",
        "    if len(prediction_list[i]) < len(caption_list[i]):\n",
        "        for n in range(len(caption_list[i])):\n",
        "            if n >= len(prediction_list[i]):\n",
        "                info_ += \"\\t\\t{:10s} \\t-->\\t {:10s}\\n\".format(vocab.idx2word[caption_list[i][n]], \"None\")\n",
        "                count += 1\n",
        "            elif prediction_list[i][n] != caption_list[i][n]:\n",
        "                info_ += \"\\t\\t{:10s} \\t-->\\t {:10s}\\n\".format(vocab.idx2word[caption_list[i][n]], vocab.idx2word[prediction_list[i][n]])\n",
        "                count += 1\n",
        "            else:\n",
        "                pass\n",
        "    \n",
        "    if count > 0:\n",
        "        info += info_\n",
        "\n",
        "#with open(\"./compare.txt\", \"w+\") as file:\n",
        "    #file.write(info)\n",
        "print(info)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   7/ 175] :\n",
            "\t\tbtn-green  \t-->\t btn-orange\n",
            "\t\t<unk>      \t-->\t double    \n",
            "\t\tbtn-orange \t-->\t btn-green \n",
            "\t\t}          \t-->\t double    \n",
            "\t\t<END>      \t-->\t {         \n",
            "\t\tNone       \t-->\t small-title\n",
            "\t\tNone       \t-->\t ,         \n",
            "\t\tNone       \t-->\t text      \n",
            "\t\tNone       \t-->\t ,         \n",
            "\t\tNone       \t-->\t btn-red   \n",
            "\t\tNone       \t-->\t }         \n",
            "\t\tNone       \t-->\t }         \n",
            "\t\tNone       \t-->\t <END>     \n",
            "[  30/ 175] :\n",
            "\t\tbtn-orange \t-->\t btn-red   \n",
            "\t\tbtn-green  \t-->\t btn-orange\n",
            "\t\tbtn-red    \t-->\t btn-orange\n",
            "\t\tbtn-red    \t-->\t btn-orange\n",
            "\t\tbtn-orange \t-->\t btn-red   \n",
            "\t\tquadruple  \t-->\t <unk>     \n",
            "\t\tbtn-green  \t-->\t btn-orange\n",
            "\t\tquadruple  \t-->\t }         \n",
            "\t\t{          \t-->\t <END>     \n",
            "\t\tsmall-title \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\ttext       \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\tbtn-green  \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\tquadruple  \t-->\t None      \n",
            "\t\t{          \t-->\t None      \n",
            "\t\tsmall-title \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\ttext       \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\tbtn-red    \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\tquadruple  \t-->\t None      \n",
            "\t\t{          \t-->\t None      \n",
            "\t\tsmall-title \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\ttext       \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\tbtn-red    \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t<END>      \t-->\t None      \n",
            "[ 101/ 175] :\n",
            "\t\tbtn-green  \t-->\t btn-orange\n",
            "\t\tbtn-orange \t-->\t btn-green \n",
            "\t\tbtn-green  \t-->\t btn-orange\n",
            "\t\tdouble     \t-->\t <unk>     \n",
            "\t\tdouble     \t-->\t }         \n",
            "\t\t{          \t-->\t <END>     \n",
            "\t\tsmall-title \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\ttext       \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\tbtn-orange \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t<END>      \t-->\t None      \n",
            "[ 102/ 175] :\n",
            "\t\tquadruple  \t-->\t double    \n",
            "\t\tquadruple  \t-->\t double    \n",
            "\t\tquadruple  \t-->\t }         \n",
            "\t\t{          \t-->\t <END>     \n",
            "\t\tsmall-title \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\ttext       \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\tbtn-green  \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\tquadruple  \t-->\t None      \n",
            "\t\t{          \t-->\t None      \n",
            "\t\tsmall-title \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\ttext       \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\tbtn-green  \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t<END>      \t-->\t None      \n",
            "[ 105/ 175] :\n",
            "\t\tdouble     \t-->\t quadruple \n",
            "\t\tbtn-green  \t-->\t btn-orange\n",
            "\t\tdouble     \t-->\t quadruple \n",
            "\t\tbtn-red    \t-->\t btn-green \n",
            "\t\t}          \t-->\t quadruple \n",
            "\t\trow        \t-->\t {         \n",
            "\t\t{          \t-->\t small-title\n",
            "\t\tquadruple  \t-->\t ,         \n",
            "\t\t{          \t-->\t text      \n",
            "\t\tsmall-title \t-->\t ,         \n",
            "\t\t,          \t-->\t btn-red   \n",
            "\t\ttext       \t-->\t }         \n",
            "\t\t,          \t-->\t quadruple \n",
            "\t\tbtn-green  \t-->\t {         \n",
            "\t\t}          \t-->\t small-title\n",
            "\t\tquadruple  \t-->\t ,         \n",
            "\t\t{          \t-->\t text      \n",
            "\t\tsmall-title \t-->\t ,         \n",
            "\t\t,          \t-->\t btn-orange\n",
            "\t\ttext       \t-->\t }         \n",
            "\t\t,          \t-->\t }         \n",
            "\t\tbtn-green  \t-->\t row       \n",
            "\t\t}          \t-->\t {         \n",
            "\t\tquadruple  \t-->\t <unk>     \n",
            "\t\tbtn-orange \t-->\t btn-green \n",
            "\t\tquadruple  \t-->\t }         \n",
            "\t\t{          \t-->\t <END>     \n",
            "\t\tsmall-title \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\ttext       \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\tbtn-green  \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t<END>      \t-->\t None      \n",
            "[ 124/ 175] :\n",
            "\t\tbtn-green  \t-->\t btn-orange\n",
            "\t\tdouble     \t-->\t <unk>     \n",
            "\t\tdouble     \t-->\t }         \n",
            "\t\t{          \t-->\t <END>     \n",
            "\t\tsmall-title \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\ttext       \t-->\t None      \n",
            "\t\t,          \t-->\t None      \n",
            "\t\tbtn-orange \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t}          \t-->\t None      \n",
            "\t\t<END>      \t-->\t None      \n",
            "\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
